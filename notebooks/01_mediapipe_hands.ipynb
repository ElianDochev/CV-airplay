{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2b09ed7",
   "metadata": {},
   "source": [
    "# 01 - MediaPipe Hands Detection\n",
    "\n",
    "This notebook demonstrates **real-time hand landmark detection** using the\n",
    "**MediaPipe Tasks Vision API**.\n",
    "\n",
    "**Goal of this notebook:**\n",
    "- Verify that the camera works\n",
    "- Detect up to **2 hands**\n",
    "- Visualize the **21 hand landmarks**\n",
    "- Quit cleanly with **Q**\n",
    "\n",
    "> No gesture logic or control mapping is implemented here.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c470c74",
   "metadata": {},
   "source": [
    "### Imports\n",
    "\n",
    "Basic libraries required for camera access and MediaPipe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d77424",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import time\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344f65c6",
   "metadata": {},
   "source": [
    "### MediaPipe HandLandmarker Model\n",
    "\n",
    "Download the official MediaPipe hand landmark model **only if it is not already present**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219d697a",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = Path(\"hand_landmarker.task\")\n",
    "\n",
    "if not MODEL_PATH.exists():\n",
    "    !wget -O hand_landmarker.task https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task\n",
    "else:\n",
    "    print(\"hand_landmarker.task already exists\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e9d4ce2",
   "metadata": {},
   "source": [
    "### HandLandmarker Initialization (Tasks API)\n",
    "\n",
    "Initialize the MediaPipe **HandLandmarker** using the Tasks API.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a58e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mediapipe.tasks import python\n",
    "from mediapipe.tasks.python import vision\n",
    "\n",
    "base_options = python.BaseOptions(\n",
    "    model_asset_path=str(MODEL_PATH)\n",
    ")\n",
    "\n",
    "options = vision.HandLandmarkerOptions(\n",
    "    base_options=base_options,\n",
    "    num_hands=2,\n",
    "    min_hand_detection_confidence=0.7,\n",
    "    min_hand_presence_confidence=0.7\n",
    ")\n",
    "\n",
    "detector = vision.HandLandmarker.create_from_options(options)\n",
    "\n",
    "print(\"MediaPipe Tasks (Hands) successfully initialized!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a31f368",
   "metadata": {},
   "source": [
    "### Real-Time Camera Test\n",
    "\n",
    "This section opens the webcam and displays detected hand landmarks\n",
    "in real time.\n",
    "\n",
    "Press **Q** to quit.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c341341",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    raise RuntimeError(\"Cannot open camera\")\n",
    "\n",
    "prev_time = 0\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Failed to read frame\")\n",
    "            break\n",
    "\n",
    "        frame = cv2.flip(frame, 1)\n",
    "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        mp_image = mp.Image(image_format=mp.ImageFormat.SRGB, data=rgb_frame)\n",
    "\n",
    "        result = detector.detect(mp_image)\n",
    "        if result.hand_landmarks:\n",
    "            for hand_landmarks in result.hand_landmarks:\n",
    "                for lm in hand_landmarks:\n",
    "                    x = int(lm.x * frame.shape[1])\n",
    "                    y = int(lm.y * frame.shape[0])\n",
    "                    cv2.circle(frame, (x, y), 4, (0, 0, 255), -1)\n",
    "\n",
    "        curr_time = time.time()\n",
    "        fps = 1 / (curr_time - prev_time) if prev_time else 0\n",
    "        prev_time = curr_time\n",
    "        cv2.putText(frame, f\"FPS: {int(fps)}\", (10, 30),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
    "\n",
    "        cv2.imshow(\"MediaPipe Hands\", frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "finally:\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    print(\"Camera closed cleanly\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
