{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26f2037e",
   "metadata": {},
   "source": [
    "# 02 — Landmarks Analysis\n",
    "\n",
    "This notebook helps you analyze **hand landmarks** detected by MediaPipe Tasks.\n",
    "\n",
    "Goals:\n",
    "- Print landmark coordinates for each hand\n",
    "- Calculate distances and angles between points\n",
    "- Visualize hands in real-time for debugging\n",
    "\n",
    "Press **Q** to quit the camera feed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf92a76",
   "metadata": {},
   "source": [
    "### Imports\n",
    "\n",
    "Libraries required for:\n",
    "- Webcam access and visualization\n",
    "- MediaPipe Tasks API (Hands Landmarker)\n",
    "- Landmark geometry analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9d3e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "from mediapipe.tasks import python\n",
    "from mediapipe.tasks.python import vision\n",
    "\n",
    "import math\n",
    "import mediapipe as mp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ca1581",
   "metadata": {},
   "source": [
    "### Hand Landmarker setup\n",
    "\n",
    "Downloads the MediaPipe hand landmark model if needed  \n",
    "and initializes the Hands detector (Tasks API)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82da6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = Path(\"hand_landmarker.task\")\n",
    "\n",
    "if not MODEL_PATH.exists():\n",
    "    !wget -O hand_landmarker.task https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task\n",
    "else:\n",
    "    print(\"hand_landmarker.task already exists\")\n",
    "\n",
    "base_options = python.BaseOptions(\n",
    "    model_asset_path=str(MODEL_PATH)\n",
    ")\n",
    "\n",
    "options = vision.HandLandmarkerOptions(\n",
    "    base_options=base_options,\n",
    "    num_hands=2,\n",
    "    min_hand_detection_confidence=0.7,\n",
    "    min_hand_presence_confidence=0.7\n",
    ")\n",
    "\n",
    "detector = vision.HandLandmarker.create_from_options(options)\n",
    "\n",
    "print(\"MediaPipe Tasks (Hands) successfully initialized!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f82b4c77",
   "metadata": {},
   "source": [
    "### Real-time hand landmarks visualization and analysis\n",
    "\n",
    "Captures the webcam stream, detects hand landmarks using MediaPipe Tasks,\n",
    "draws landmark points and connections, and computes a simple pinch distance\n",
    "(thumb tip ↔ index tip) for each detected hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3557464",
   "metadata": {},
   "outputs": [],
   "source": [
    "HAND_CONNECTIONS = [\n",
    "    (0, 1), (1, 2), (2, 3), (3, 4),             # Thumb\n",
    "    (0, 5), (5, 6), (6, 7), (7, 8),             # Index finger\n",
    "    (9, 10), (10, 11), (11, 12),                # Middle finger\n",
    "    (13, 14), (14, 15), (15, 16),               # Ring finger\n",
    "    (0, 17), (17, 18), (18, 19), (19, 20),      # Pinky\n",
    "    (5, 9), (9, 13), (13, 17)                   # Palm\n",
    "]\n",
    "\n",
    "# Computes the Euclidean distance between two landmarks\n",
    "def get_distance(p1, p2):\n",
    "    return math.sqrt((p1.x - p2.x)**2 + (p1.y - p2.y)**2)\n",
    "\n",
    "# Camera initialization\n",
    "cap = cv2.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    raise RuntimeError(\"Cannot open camera\")\n",
    "\n",
    "last_print_time = 0\n",
    "\n",
    "try:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Failed to read frame\")\n",
    "            break\n",
    "\n",
    "        # Mirror view for a more natural interaction\n",
    "        frame = cv2.flip(frame, 1)\n",
    "        h, w, _ = frame.shape\n",
    "\n",
    "        # Convert frame to RGB (required by MediaPipe)\n",
    "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        mp_image = mp.Image(\n",
    "            image_format=mp.ImageFormat.SRGB,\n",
    "            data=rgb_frame\n",
    "        )\n",
    "\n",
    "        # Hand landmark detection\n",
    "        result = detector.detect(mp_image)\n",
    "\n",
    "        if result.hand_landmarks:\n",
    "            for hand_idx, landmarks in enumerate(result.hand_landmarks):\n",
    "                \n",
    "                # 1. Draw hand connections (skeleton)\n",
    "                for start_idx, end_idx in HAND_CONNECTIONS:\n",
    "                    start_pt = (\n",
    "                        int(landmarks[start_idx].x * w),\n",
    "                        int(landmarks[start_idx].y * h)\n",
    "                    )\n",
    "                    end_pt = (\n",
    "                        int(landmarks[end_idx].x * w),\n",
    "                        int(landmarks[end_idx].y * h)\n",
    "                    )\n",
    "                    cv2.line(frame, start_pt, end_pt, (0, 255, 0), 2)\n",
    "\n",
    "                # 2. Draw landmark points\n",
    "                for lm in landmarks:\n",
    "                    cx, cy = int(lm.x * w), int(lm.y * h)\n",
    "                    cv2.circle(frame, (cx, cy), 5, (0, 0, 255), -1)\n",
    "\n",
    "                # 3. Simple analysis: pinch distance (thumb ↔ index)\n",
    "                dist_pinch = get_distance(landmarks[4], landmarks[8])\n",
    "\n",
    "                # Hand label: Left / Right\n",
    "                hand_label = result.handedness[hand_idx][0].category_name\n",
    "\n",
    "                # Display pinch distance on screen\n",
    "                cv2.putText(\n",
    "                    frame,\n",
    "                    f\"{hand_label} - Pinch: {dist_pinch:.2f}\",\n",
    "                    (10, 50 + hand_idx * 30),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                    1,\n",
    "                    (255, 0, 0),\n",
    "                    2\n",
    "                )\n",
    "\n",
    "        # Display the camera feed\n",
    "        cv2.imshow(\"MediaPipe Hands\", frame)\n",
    "\n",
    "        # Exit on 'q'\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "finally:\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    print(\"Camera closed cleanly\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
